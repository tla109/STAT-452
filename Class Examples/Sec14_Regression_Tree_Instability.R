#########################################################################
# Demonatration of the utility of bootstrap aggregation
#
### Using our 4-th order polynomial model from earlier lectures
#
# Creating 100-obs training set and 1000-obs test set
# Plotting data with a regression tree
# Showing how variable regression tree is in 100 bootstrap resamples
#   Aggregating into

# Set starting point for random number generation
set.seed(26891074)
library(rpart)
# Start with a population:
# y = beta0 + beta1 x + beta2 x^2 + beta3 x^3 + beta4 x^4 + epsilon, epsilon~N(0,sigma^2)
#   Create the parameters of the population regression line
beta0 <- 2
beta1 <- 13 / 5
beta2 <- 8 / 15
beta3 <- -8 / 5
beta4 <- -8 / 15
sigma <- .3
n <- 100
# Training data
x <- runif(n, min = -1, max = 1)
epsilon <- rnorm(n = n, mean = 0, sd = sigma)
y <- beta0 + beta1 * x + beta2 * x^2 + beta3 * x^3 + beta4 * x^4 + epsilon


curve(
  expr = beta0 + beta1 * x + beta2 * x^2 + beta3 * x^3 + beta4 * x^4,
  from = -1, to = 1, col = "red", lwd = 2, ylim = c(0, 4.2), ylab = "y",
  main = "100 points from 4-ord poly with reg tree"
)
points(x = x, y = y, col = "gray")

#  Test data: n.t obs
x.t <- seq(from = -1, to = 1, by = 1 / 500)
n.t <- length(x.t)
epsilon.t <- rnorm(n = n.t, mean = 0, sd = sigma)
y.t <- beta0 + beta1 * x.t + beta2 * x.t^2 + beta3 * x.t^3 + beta4 * x.t^4 + epsilon.t


## Now fit regression tree and add to plot
x.tree <- rpart(y ~ x, method = "anova", cp = 0)
cpt <- x.tree$cptable

# Find location of minimum error
minrow <- which.min(cpt[, 4])
# Take geometric mean of cp values at min error and one step up
cplow.min <- cpt[minrow, 1]
cpup.min <- ifelse(minrow == 1, yes = 1, no = cpt[minrow - 1, 1])
cp.min <- sqrt(cplow.min * cpup.min)

# Do pruning
pr.prune.min <- prune(x.tree, cp = cp.min)


# Plot this line
preds <- predict(pr.prune.min, newdata = data.frame(x = x.t))
points(x = x.t, y = preds, cex = 0.2, col = "blue")


# Now bootstrap that 100 times
reps <- 100
pred.tree <- matrix(NA, nrow = n.t, ncol = reps)
pred.lm <- matrix(NA, nrow = n.t, ncol = reps)

for (i in 1:reps) {
  samp <- sample.int(n, size = n, replace = TRUE)
  train <- data.frame(x = x[samp], y = y[samp])

  pr.tree1 <- rpart(y ~ x, method = "anova", data = train, cp = 0)
  cpt1 <- pr.tree1$cptable

  # Find location of minimum error
  minrow1 <- which.min(cpt1[, 4])
  # Take geometric mean of cp values at min error and one step up
  cplow.min1 <- cpt1[minrow1, 1]
  cpup.min1 <- ifelse(minrow1 == 1, yes = 1, no = cpt1[minrow1 - 1, 1])
  cp.min1 <- sqrt(cplow.min1 * cpup.min1)

  # Do pruning each way
  pr.prune.min1 <- prune(pr.tree1, cp = cp.min1)

  # Plot these points line
  preds1 <- predict(pr.prune.min1, newdata = data.frame(x = x.t))

  pred.tree[, i] <- preds1
  pred.lm[, i] <- predict(lm(y ~ x, data = train), newdata = data.frame(x = x.t))
}

par(mfrow = c(1, 2))
plot(x = x, y = y, col = "gray", main = "Reg Tree on Bootstrap Poly-4 Data")
for (i in 1:reps) {
  points(x = x.t, y = pred.tree[, i], cex = 0.2, col = "lightblue")
}
points(x = x, y = y, col = "gray")
curve(
  expr = beta0 + beta1 * x + beta2 * x^2 + beta3 * x^3 + beta4 * x^4,
  from = -1, to = 1, col = "red", lwd = 2, ylim = c(0, 4.2), add = TRUE
)

plot(x = x, y = y, col = "gray", main = "Lin Reg on Bootstrap Poly-4 Data")
for (i in 1:reps) {
  points(x = x.t, y = pred.lm[, i], cex = 0.2, col = "lightblue")
}
points(x = x, y = y, col = "gray")
curve(
  expr = beta0 + beta1 * x + beta2 * x^2 + beta3 * x^3 + beta4 * x^4,
  from = -1, to = 1, col = "red", lwd = 2, ylim = c(0, 4.2), add = TRUE
)

par(mfrow = c(1, 2))
plot(x = x, y = y, col = "gray", main = "Bootstrap Aggregated Reg Tree")
for (i in 1:reps) {
  points(x = x.t, y = pred.tree[, i], cex = 0.2, col = "lightblue")
}
points(x = x, y = y, col = "gray")
curve(
  expr = beta0 + beta1 * x + beta2 * x^2 + beta3 * x^3 + beta4 * x^4,
  from = -1, to = 1, col = "red", lwd = 2, ylim = c(0, 4.2), add = TRUE
)

mean.tree <- apply(pred.tree, 1, mean)
points(x = x.t, y = mean.tree, col = "blue", cex = 0.5)

plot(x = x, y = y, col = "gray", main = "Bootstrap Aggregated Lin reg")
for (i in 1:reps) {
  points(x = x.t, y = pred.lm[, i], cex = 0.2, col = "lightblue")
}
points(x = x, y = y, col = "gray")
curve(
  expr = beta0 + beta1 * x + beta2 * x^2 + beta3 * x^3 + beta4 * x^4,
  from = -1, to = 1, col = "red", lwd = 2, ylim = c(0, 4.2), add = TRUE
)

mean.lm <- apply(pred.lm, 1, mean)
points(x = x.t, y = mean.lm, col = "blue", cex = 0.5)


# Compute MSPEs on test set for true polynimial
#  Lin Model, Tree, Boot-LM, and Boot-tree
(rMSPE.tree <- sqrt(mean((preds - y.t)^2)))
(rMSPE.boot.tree <- sqrt(mean((mean.tree - y.t)^2)))
(rMSPE.lm <- sqrt(mean((predict(lm(y ~ x), data.frame(x = x.t)) - y.t)^2)))
(rMSPE.boot.lm <- sqrt(mean((mean.lm - y.t)^2)))
(rMSPE.poly <- sqrt(mean((predict(lm(y ~ poly(x, 4)), data.frame(x = x.t)) - y.t)^2)))

