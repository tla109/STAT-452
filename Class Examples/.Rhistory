### for scaling the validation set to match the training set).
### Rescale x1 using the means and SDs of x2
scale.1 <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- mean(x2[, col])
b <- sd(x2[, col])
x1[, col] <- (x1[, col] - a) / b
}
x1
}
### Rescale our training and validation sets
X.train <- scale.1(X.train.raw, X.train.raw)
X.valid <- scale.1(X.valid.raw, X.train.raw) # Watch the order
### Now we can fit a KNN model using the knn function in the FNN
### package. The syntax of the knn function is a bit different from
### what we're used to. The first two inputs are the training and
### validation predictor matrices. The third input is the class labels
### for the training set. We can also set k to the number of
### neighbours we want. The function then outputs predicted class
### labels for the validation set. Let's use 1 neighbour.
pred.knn <- knn(X.train, X.valid, Y.train, k = 1)
### Let's make a confusion matrix. We get this using the table()
### function and providing both the predicted and true class labels
### for the validation set. We can also set the axis labels using
### the dnn input.
table(pred.knn, Y.valid, dnn = c("Predicted", "Observed"))
### Next, let's get the misclassification rate
(misclass.knn <- mean(pred.knn != Y.valid))
(se.knn <- sapply(misclass.knn, function(r) {
sqrt(r * (1 - r) / nrow(X.train))
}))
### Rescale the columns of x1 so that the columns of x2 fall between 0 and 1
rescale <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- min(x2[, col])
b <- max(x2[, col])
x1[, col] <- (x1[, col] - a) / (b - a)
}
x1
}
### Create copies of our datasets and rescale
data.train.scale <- set1
data.valid.scale <- set2
data.train.scale[, -19] <- rescale(data.train.scale[, -19], set1[, -19])
data.valid.scale[, -19] <- rescale(data.valid.scale[, -19], set1[, -19])
summary(data.train.scale[,1:3])
summary(data.train.scale[,1:3])
library(nnet)
library(car)
library(glmnet)
library(MASS)
fit.log.nnet <- multinom(class ~ ., data = data.train.scale)
Anova(fit.log.nnet)
pred.log.nnet <- predict(fit.log.nnet, data.valid.scale)
(misclass.log.nnet <- mean(pred.log.nnet != Y.valid))
(misclass.log.se <- sapply(misclass.log.nnet, function(r) {
sqrt(r * (1 - r) / nrow(X.train))
}))
table(Y.valid, pred.log.nnet, ### Confusion matrix
dnn = c("Observed", "Predicted")
)
misclass.log.nnet
### The glmnet() function uses predictor matrix/response vector syntax,
### so we need to extract these from our training and validation sets.
### We also have to convert the predictors to a matrix using the
### as.matrix() function.
X.train.scale <- as.matrix(data.train.scale[, -19])
Y.train <- data.train.scale[, 19]
X.valid.scale <- as.matrix(data.valid.scale[, -19])
Y.valid <- data.valid.scale[, 19]
### While we're looking at the glmnet package, let's do LASSO. We need to
### choose lambda using CV. Fortunately, the cv.glmnet() function does this
### for us. The syntax for cv.glmnet() is the same as for glmnet().
fit.CV.lasso <- cv.glmnet(X.train.scale, Y.train, family = "multinomial")
### The CV-min values are stored in the output from
### cv.glmnet()
lambda.min <- fit.CV.lasso$lambda.min
### Let's check which predictors are included in each "best" model. We
### can get the coefficients using the coef() function, setting s to
### the appropriate lambda value.
coef(fit.CV.lasso, s = lambda.min)
### Now we can get predictions for both "best" models
pred.lasso.min <- predict(fit.CV.lasso, X.valid.scale,
s = lambda.min,
type = "class"
)
table(Y.valid, pred.lasso.min, dnn = c("Obs", "Pred"))
(miss.lasso.min <- mean(Y.valid != pred.lasso.min))
(se.miss.lasso.min <- sapply(miss.lasso.min, function(r) {
sqrt(r * (1 - r) / nrow(X.train.scale))
}))
### For discriminant analysis, it's best to scale predictors
### to have mean 0 and SD 1 (this makes the results easier to
### interpret). We can do this using using the following function.
### Rescale x1 using the means and SDs of x2
scale.1 <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- mean(x2[, col])
b <- sd(x2[, col])
x1[, col] <- (x1[, col] - a) / b
}
x1
}
X.train.DA <- scale.1(set1[, -19], set1[, -19])
X.valid.DA <- scale.1(set2[, -19], set1[, -19])
class.col <- ifelse(set1$class=='2D', y = 53,
n = ifelse(set1$class=='4D', y = 68, n = ifelse(set1$class=='BUS',y=203,n=464)))
### Fit an LDA model using the lda() funtion from the MASS package. This
### function uses predictor/response syntax.
fit.lda <- lda(X.train.DA, Y.train)
### We can plot the data using the linear discriminants. It's best to
### include colors. Let's just recycle the colors from above.
### There is no simple way to change the axis labels. Sometimes we just need
### to live with the defaults.
plot(fit.lda, col = class.col)
### We get predictions by extracting the class object from the predict()
### function's output.
pred.lda <- predict(fit.lda, X.valid.DA)$class
table(Y.valid, pred.lda, dnn = c("Obs", "Pred"))
(miss.lda <- mean(Y.valid != pred.lda))
(se.miss.lda <- sapply(miss.lda, function(r) {
sqrt(r * (1 - r) / nrow(X.train.DA))
}))
### attempting SVM
library(e1071)
set.seed(1)
data.train.bv = data.train[,c(10,11,21)]
remove(list=ls())
## water quality data, is_safe is a binary variable 0 or 1
# ammonia is incorrectly labeled as character
water = read.csv("waterQuality1.csv", header = TRUE)
summary(water)
water$ammonia = as.numeric(water$ammonia)
water$is_safe = as.numeric(water$is_safe)
water = na.omit(water)
water$is_safe = as.factor(water$is_safe)
summary(water)
water$ammonia[which(water$ammonia < 0)] = NA
water = na.omit(water)
summary(water)
dim(water)
### first fit a logistic regression
library(nnet)
library(MASS)
### need to rescale
rescale <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- min(x2[, col])
b <- max(x2[, col])
x1[, col] <- (x1[, col] - a) / (b - a)
}
x1
}
p.train <- 0.75
n <- nrow(water)
n.train <- floor(p.train * n)
ind.random <- sample(1:n)
data.train <- water[ind.random <= n.train, ]
data.valid <- water[ind.random > n.train, ]
Y.valid <- data.valid[, 21]
data.train.scale <- data.train
data.valid.scale <- data.valid
data.train.scale[, -21] <- rescale(data.train.scale[, -21], data.train[, -21])
data.valid.scale[, -21] <- rescale(data.valid.scale[, -21], data.train[, -21])
X.train.scale <- as.matrix(data.train.scale[, -21])
Y.train <- data.train.scale[, 21]
X.valid.scale <- as.matrix(data.valid.scale[, -21])
Y.valid <- data.valid.scale[, 21]
fit.log.nnet <- multinom(is_safe ~ ., data = data.train.scale)
summary(fit.log.nnet)
### Next, let's investigate the LR's performance on the test set
## probabilities
pred.log.nnet.probs <- predict(fit.log.nnet, data.valid.scale, type = 'probs')
pred.log.nnet <- predict(fit.log.nnet, data.valid.scale)
table(Y.valid, pred.log.nnet, ### Confusion matrix
dnn = c("Observed", "Predicted")
)
(misclass.log.nnet <- mean(pred.log.nnet != Y.valid)) ### Misclass rate
## misclass rate is about 10%
## now to LDR
### For discriminant analysis, it's best to scale predictors
### to have mean 0 and SD 1 (this makes the results easier to
### interpret). We can do this using using the following function.
### Rescale x1 using the means and SDs of x2
scale.1 <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- mean(x2[, col])
b <- sd(x2[, col])
x1[, col] <- (x1[, col] - a) / b
}
x1
}
X.train.DA <- scale.1(data.train[, -21], data.train[, -21])
X.valid.DA <- scale.1(data.valid[, -21], data.train[, -21])
### Fit an LDA model using the lda() funtion from the MASS package. This
### function uses predictor/response syntax.
fit.lda <- lda(X.train.DA, Y.train)
### We get predictions by extracting the class object from the predict()
### function's output.
## this gets the probability of predicting a 1
pred.lda.probs <- (predict(fit.lda, X.valid.DA)$posterior)[,2]
pred.lda <- predict(fit.lda, X.valid.DA)$class
table(Y.valid, pred.lda, dnn = c("Obs", "Pred"))
(miss.lda <- mean(Y.valid != pred.lda))
### attempting ROC Curve
library(ROCR)
rocplot =function(pred, truth, ...){
predob = prediction(pred, truth)
perf = performance (predob, "tpr", "fpr")
plot(perf,...)}
rocplot(pred.log.nnet.probs, Y.valid, main = "Logistic Regression ROC Curve")
(performance(prediction(pred.log.nnet.probs, Y.valid), measure = "auc"))@y.values[[1]]
rocplot(pred.lda.probs, Y.valid, main = "Linear Discriminant ROC Curve")
(performance(prediction(pred.lda.probs, Y.valid), measure = "auc"))@y.values[[1]]
### attempting SVM
library(e1071)
set.seed(1)
data.train.bv = data.train[,c(10,11,21)]
data.valid.bv = data.valid[,c(10,11,21)]
Y.valid.bv = data.valid[,21]
## cost = 1
begin = Sys.time()
svmfit = svm(is_safe ~., data=data.train.bv, kernel = "radial", gamma = 1, cost=1)
summary(svmfit)
(Sys.time() - begin)
## cost = 1e5
begin = Sys.time()
svmfit2 = svm(is_safe ~., data=data.train.bv, kernel = "radial", gamma = 1, cost=1e5)
summary(svmfit2)
(Sys.time() - begin)
begin = Sys.time()
tune.out=tune(svm, is_safe ~., data=data.train.bv, kernel = "radial",
ranges =list(cost=c(0.1 ,1 ,10 ,100 ,1000),
gamma=c(0.5,1,2,3,4) ))
summary(tune.out)
(Sys.time() - begin)
## select best SVM model
table(true=Y.valid, pred=predict(tune.out$best.model,
newdata = data.valid))
## ROC Curve
svmfit.opt= svm(is_safe ~., data=data.train, kernel = "radial",
gamma = 2, cost = 1, decision.values = T)
fitted =attributes(predict(svmfit.opt, data.valid, decision.values=TRUE))$decision.values
rocplot(fitted, Y.valid, main = "SVM")
(performance(prediction(fitted, Y.valid), measure = "auc"))@y.values[[1]]
x=matrix (rnorm (200*2) , ncol =2)
x[1:100 ,]=x[1:100 ,]+2
x[101:150 ,]= x[101:150 ,] -2
x
y=c(rep (1 ,150) ,rep (2 ,50) )
dat=data.frame(x=x,y=as.factor (y))
plot(x, col=y)
plot(x, col=y)\
plot(x, col=y)\
plot(x, col=y)
setwd("C:/Users/terry/Desktop/STAT-452/Class Examples")
# Multinomial Logistic Regression on Wheat Data
##########
# Enter data and do some processing
wheat <- read.csv("Datasets/wheat.csv")
head(wheat)
summary(wheat)
# Variable "type" is the response variable.  "class" is another explanatory.
class(wheat$type)
wheat$type <- as.factor(wheat$type)
wheat$class <- as.factor(wheat$class)
summary(wheat)
setwd("C:/Users/terry/Desktop/STAT-452/Tut")
### Read-in and process the data
source("Read_Wine_Data_Class.R")
data
anova(fit.log.nnet)
library(car) # For ANOVA after logistic regression with nnet
anova(fit.log.nnet)
library(car)
anova(fit.log.nnet)
anova(fit.log.lda)
anova(fit.lda)
summary(fit.log.nnet)
Anova(fit.log.nnet)
svm
remove(list=ls())
### Read-in and process the data
source("Read_Wine_Data_Class.R")
### Activate packages
library(nnet) # For logistic regression
library(car) # For ANOVA after logistic regression with nnet
library(glmnet) # For logistic regression and LASSO
library(MASS) # For discriminant analysis
### Set random seed, using Mersenne-Twister for compatibility.
set.seed(46536737, kind = "Mersenne-Twister")
### Split the data into training and validation sets
p.train <- 0.75
n <- nrow(data)
n.train <- floor(p.train * n)
ind.random <- sample(1:n)
data.train <- data[ind.random <= n.train, ]
data.valid <- data[ind.random > n.train, ]
Y.valid <- data.valid[, 1]
svmfit = svm(quality ~., data=data.train, kernel = "radial", gamma = 1, cost=1)
data.train$quality
setwd("C:/Users/terry/Desktop/STAT-452/Class Examples")
# Multinomial Logistic Regression on Wheat Data
##########
# Enter data and do some processing
wheat <- read.csv("Datasets/wheat.csv")
head(wheat)
summary(wheat)
# Variable "type" is the response variable.  "class" is another explanatory.
class(wheat$type)
wheat$type <- as.factor(wheat$type)
wheat$class <- as.factor(wheat$class)
summary(wheat)
?tune
set.seed (1)
x=matrix (rnorm (200*2) , ncol =2)
x[1:100 ,]=x[1:100 ,]+2
x[101:150 ,]= x[101:150 ,] -2
y=c(rep (1 ,150) ,rep (2 ,50) )
dat=data.frame(x=x,y=as.factor(y))
plot(x, col=y)
train=sample (200 ,100)
svmfit =svm(y~., data=dat [train ,], kernel =" radial ", gamma =1,
cost =1)
svmfit =svm(y~., data=dat [train ,], kernel ="radial", gamma =1,
cost =1)
plot(svmfit , dat[train ,])
set.seed (1)
x=matrix (rnorm (200*2) , ncol =2)
x[1:100 ,]=x[1:100 ,]+2
x[101:150 ,]= x[101:150 ,] -2
y=c(rep (1 ,150) ,rep (2 ,50) )
dat=data.frame(x=x,y=as.factor(y))
plot(x, col=y)
train=sample (200 ,100)
svmfit =svm(y~., data=dat [train ,], kernel ="radial", gamma =1,
cost =1)
plot(svmfit , dat[train ,])
summary (svmfit )
svmfit =svm(y~., data=dat [train ,], kernel =" radial ",gamma =1,
cost=1e5)
set.seed (1)
x=matrix (rnorm (200*2) , ncol =2)
x[1:100 ,]=x[1:100 ,]+2
x[101:150 ,]= x[101:150 ,] -2
y=c(rep (1 ,150) ,rep (2 ,50) )
dat=data.frame(x=x,y=as.factor(y))
plot(x, col=y)
train=sample (200 ,100)
svmfit =svm(y~., data=dat [train ,], kernel ="radial", gamma =1,
cost =1)
plot(svmfit , dat[train ,])
summary (svmfit )
svmfit =svm(y~., data=dat [train ,], kernel ="radial",gamma =1,
cost=1e5)
plot(svmfit ,dat [train ,])
tune.out=tune(svm , y~., data=dat[train ,], kernel ="radial",
ranges =list(cost=c(0.1 ,1 ,10 ,100 ,1000),
gamma=c(0.5,1,2,3,4) ))
summary (tune.out)
table(true=dat[-train ,"y"], pred=predict (tune.out$best .model ,
table(true=dat[-train ,"y"], pred=predict (tune.out$best.model ,
newdata =dat[-train ,]))
remove(list=ls())
## water quality data, is_safe is a binary variable 0 or 1
# ammonia is incorrectly labeled as character
water = read.csv("waterQuality1.csv", header = TRUE)
summary(water)
water$ammonia = as.numeric(water$ammonia)
water$is_safe = as.numeric(water$is_safe)
water = na.omit(water)
water$is_safe = as.factor(water$is_safe)
summary(water)
water$ammonia[which(water$ammonia < 0)] = NA
water = na.omit(water)
summary(water)
dim(water)
### first fit a logistic regression
library(nnet)
library(MASS)
### need to rescale
rescale <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- min(x2[, col])
b <- max(x2[, col])
x1[, col] <- (x1[, col] - a) / (b - a)
}
x1
}
p.train <- 0.75
n <- nrow(water)
n.train <- floor(p.train * n)
ind.random <- sample(1:n)
data.train <- water[ind.random <= n.train, ]
data.valid <- water[ind.random > n.train, ]
Y.valid <- data.valid[, 21]
data.train.scale <- data.train
data.valid.scale <- data.valid
data.train.scale[, -21] <- rescale(data.train.scale[, -21], data.train[, -21])
data.valid.scale[, -21] <- rescale(data.valid.scale[, -21], data.train[, -21])
X.train.scale <- as.matrix(data.train.scale[, -21])
Y.train <- data.train.scale[, 21]
X.valid.scale <- as.matrix(data.valid.scale[, -21])
Y.valid <- data.valid.scale[, 21]
fit.log.nnet <- multinom(is_safe ~ ., data = data.train.scale)
summary(fit.log.nnet)
### Next, let's investigate the LR's performance on the test set
## probabilities
pred.log.nnet.probs <- predict(fit.log.nnet, data.valid.scale, type = 'probs')
pred.log.nnet <- predict(fit.log.nnet, data.valid.scale)
table(Y.valid, pred.log.nnet, ### Confusion matrix
dnn = c("Observed", "Predicted")
)
(misclass.log.nnet <- mean(pred.log.nnet != Y.valid)) ### Misclass rate
## misclass rate is about 10%
## now to LDR
### For discriminant analysis, it's best to scale predictors
### to have mean 0 and SD 1 (this makes the results easier to
### interpret). We can do this using using the following function.
### Rescale x1 using the means and SDs of x2
scale.1 <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- mean(x2[, col])
b <- sd(x2[, col])
x1[, col] <- (x1[, col] - a) / b
}
x1
}
X.train.DA <- scale.1(data.train[, -21], data.train[, -21])
X.valid.DA <- scale.1(data.valid[, -21], data.train[, -21])
### Fit an LDA model using the lda() funtion from the MASS package. This
### function uses predictor/response syntax.
fit.lda <- lda(X.train.DA, Y.train)
### We get predictions by extracting the class object from the predict()
### function's output.
## this gets the probability of predicting a 1
pred.lda.probs <- (predict(fit.lda, X.valid.DA)$posterior)[,2]
pred.lda <- predict(fit.lda, X.valid.DA)$class
table(Y.valid, pred.lda, dnn = c("Obs", "Pred"))
(miss.lda <- mean(Y.valid != pred.lda))
### attempting ROC Curve
library(ROCR)
rocplot =function(pred, truth, ...){
predob = prediction(pred, truth)
perf = performance (predob, "tpr", "fpr")
plot(perf,...)}
rocplot(pred.log.nnet.probs, Y.valid, main = "Logistic Regression ROC Curve")
(performance(prediction(pred.log.nnet.probs, Y.valid), measure = "auc"))@y.values[[1]]
rocplot(pred.lda.probs, Y.valid, main = "Linear Discriminant ROC Curve")
(performance(prediction(pred.lda.probs, Y.valid), measure = "auc"))@y.values[[1]]
### attempting SVM
library(e1071)
set.seed(1)
## cost = 1
begin = Sys.time()
svmfit = svm(is_safe ~., data=data.train, kernel = "radial", gamma = 1, cost=1)
summary(svmfit)
plot(data.train, col = data.train[,21])
(Sys.time() - begin)
## cost = 1e5
begin = Sys.time()
svmfit2 = svm(is_safe ~., data=data.train, kernel = "radial", gamma = 1, cost=1e5)
summary(svmfit2)
(Sys.time() - begin)
begin = Sys.time()
tune.out=tune(svm, is_safe ~., data=data.train, kernel = "radial",
ranges =list(cost=c(0.1 ,1 ,10 ,100 ,1000),
gamma=c(0.5,1,2,3,4) ))
summary(tune.out)
(Sys.time() - begin)
## select best SVM model
table(true=Y.valid, pred=predict(tune.out$best.model,
newdata = data.valid))
## ROC Curve
svmfit.opt= svm(is_safe ~., data=data.train, kernel = "radial",
gamma = 2, cost = 1, decision.values = T)
fitted =attributes(predict(svmfit.opt, data.valid, decision.values=TRUE))$decision.values
rocplot(fitted, Y.valid, main = "SVM")
(performance(prediction(fitted, Y.valid), measure = "auc"))@y.values[[1]]
tune.out
## ROC Curve
svmfit.opt= svm(is_safe ~., data=data.train, kernel = "radial",
gamma = 0.5, cost = 0.1, decision.values = T)
fitted =attributes(predict(svmfit.opt, data.valid, decision.values=TRUE))$decision.values
rocplot(fitted, Y.valid, main = "SVM")
(performance(prediction(fitted, Y.valid), measure = "auc"))@y.values[[1]]
## ROC Curve
svmfit.opt= svm(is_safe ~., data=data.train, kernel = "radial",
gamma = 0.05, cost = 0.01, decision.values = T)
fitted =attributes(predict(svmfit.opt, data.valid, decision.values=TRUE))$decision.values
rocplot(fitted, Y.valid, main = "SVM")
(performance(prediction(fitted, Y.valid), measure = "auc"))@y.values[[1]]
tune.out$best.model
?tune
best.tune(tune.out)
best.tune()
tune.out$performances
summary(tune.out$best.model)
## select best SVM model and use it for prediction
pred.svm = predict(tune.out$best.model, newdata = data.valid)
table(true=Y.valid, pred=pred.svm)
(miss.svm <- mean(Y.valid != pred.svm))
pred.svm = predict(tune.out$best.model, newdata = data.valid)
table(true=Y.valid, pred=pred.svm)
(miss.svm <- mean(Y.valid != pred.svm))
rocplot(fitted, Y.valid, main = "SVM")
(performance(prediction(fitted, Y.valid), measure = "auc"))@y.values[[1]]
svmfit.opt= svm(is_safe ~., data=data.train, kernel = "radial",
gamma = 0.5, cost = 0.1, decision.values = T)
fitted =attributes(predict(svmfit.opt, data.valid, decision.values=TRUE))$decision.values
rocplot(fitted, Y.valid, main = "SVM")
(performance(prediction(fitted, Y.valid), measure = "auc"))@y.values[[1]]
