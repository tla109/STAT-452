head(set1)
head(set2)
library(FNN)
### Split up the predictor variables from the class labels.
X.train.raw = set1[, -19]
X.valid.raw = set2[, -19]
Y.train = set1[, 19]
Y.valid = set2[, 19]
### KNN is based on distances. If variables are measured on different
### scales, we can change which points are neighbours by measuring
### in different units.
### a function we can use to rescale the columns of
### a data frame to have mean 0 and SD 1. We can also use it to rescale
### a data frame based on the means and SDs of another (this is useful
### for scaling the validation set to match the training set).
### Rescale x1 using the means and SDs of x2
scale.1 <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- mean(x2[, col])
b <- sd(x2[, col])
x1[, col] <- (x1[, col] - a) / b
}
x1
}
### Rescale our training and validation sets
X.train <- scale.1(X.train.raw, X.train.raw)
X.valid <- scale.1(X.valid.raw, X.train.raw) # Watch the order
### Now we can fit a KNN model using the knn function in the FNN
### package. The syntax of the knn function is a bit different from
### what we're used to. The first two inputs are the training and
### validation predictor matrices. The third input is the class labels
### for the training set. We can also set k to the number of
### neighbours we want. The function then outputs predicted class
### labels for the validation set. Let's use 1 neighbour.
pred.knn <- knn(X.train, X.valid, Y.train, k = 1)
### Let's make a confusion matrix. We get this using the table()
### function and providing both the predicted and true class labels
### for the validation set. We can also set the axis labels using
### the dnn input.
table(pred.knn, Y.valid, dnn = c("Predicted", "Observed"))
### Next, let's get the misclassification rate
(misclass.knn <- mean(pred.knn != Y.valid))
(se.knn <- sapply(misclass.knn, function(r) {
sqrt(r * (1 - r) / nrow(X.train))
}))
fit.log.nnet
pred.log.nnet
fit.log.nnet
pred.log.nnet
misclass.log.nnet
(misclass.log.se <- sapply(misclass.knn, function(r) {
sqrt(r * (1 - r) / nrow(X.train))
}))
(misclass.log.se <- sapply(misclass.log.nnet, function(r) {
sqrt(r * (1 - r) / nrow(X.train))
}))
lambda.min
fit.CV.lasso
fit.CV.lasso$SE
fit.CV.lasso$SE.min
pred.lasso.min
summary(fit.CV.lasso)
summary(pred.lasso.min)
plot(fit.CV.lasso)
### Let's check which predictors are included in each "best" model. We
### can get the coefficients using the coef() function, setting s to
### the appropriate lambda value.
coef(fit.CV.lasso, s = lambda.min)
setwd("C:/Users/terry/Desktop/STAT-452/Homework/hw_3")
write.csv(coef(fit.CV.lasso, s = lambda.min), title = 'coef.csv')
?write.csv
write.csv(coef(fit.CV.lasso, s = lambda.min), file = 'coef.csv')
coef(fit.CV.lasso, s = lambda.min)
write.table(coef(fit.CV.lasso, s = lambda.min), file = 'coef')
x = 5
type(x)
class(x)
remove(x)
class(coef(fit.CV.lasso, s = lambda.min))
dim(coef(fit.CV.lasso, s = lambda.min))
library(nnet)
library(car)
library(glmnet)
library(MASS)
fit.log.nnet <- multinom(class ~ ., data = data.train.scale)
Anova(fit.log.nnet)
### Let's check which predictors are included in each "best" model. We
### can get the coefficients using the coef() function, setting s to
### the appropriate lambda value.
coef(fit.CV.lasso, s = lambda.min)
miss.lasso.min <- mean(Y.valid != pred.lasso.min)
(se.miss.lasso.min <- sapply(miss.lasso.min, function(r) {
sqrt(r * (1 - r) / nrow(X.train.scale))
}))
### For discriminant analysis, it's best to scale predictors
### to have mean 0 and SD 1 (this makes the results easier to
### interpret). We can do this using using the following function.
### Rescale x1 using the means and SDs of x2
scale.1 <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- mean(x2[, col])
b <- sd(x2[, col])
x1[, col] <- (x1[, col] - a) / b
}
x1
}
X.train.DA <- scale.1(data.train[, -19], data.train[, -19])
X.valid.DA <- scale.1(data.valid[, -19], data.train[, -19])
### Fit an LDA model using the lda() funtion from the MASS package. This
### function uses predictor/response syntax.
fit.lda <- lda(X.train.DA, Y.train)
### We can plot the data using the linear discriminants. It's best to
### include colors. Let's just recycle the colors from above.
### There is no simple way to change the axis labels. Sometimes we just need
### to live with the defaults.
plot(fit.lda, col = col.qual)
class.col <- ifelse(X.train.DA$class==1, y = 53,
n = ifelse(X.train.DA$class==2, y = 68, n = ifelse(X.train.DA$class==3,y=203,n=464)))
### We can plot the data using the linear discriminants. It's best to
### include colors. Let's just recycle the colors from above.
### There is no simple way to change the axis labels. Sometimes we just need
### to live with the defaults.
plot(fit.lda, col = class.col)
### We can also get histograms of the data along the main linear
### discriminant by setting type="histogram" and setting dimen=1.
plot(fit.lda, type = "histogram", dimen = 1)
plot(fit.lda, col = class.col)
plot(fit.lda, type = "histogram", dimen = 1)
### We can also add smoothed density curves to these histograms by setting
### type="both".
plot(fit.lda, type = "both", dimen = 1)
### For discriminant analysis, it's best to scale predictors
### to have mean 0 and SD 1 (this makes the results easier to
### interpret). We can do this using using the following function.
### Rescale x1 using the means and SDs of x2
scale.1 <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- mean(x2[, col])
b <- sd(x2[, col])
x1[, col] <- (x1[, col] - a) / b
}
x1
}
X.train.DA <- scale.1(data.train[, -19], data.train[, -19])
X.valid.DA <- scale.1(data.valid[, -19], data.train[, -19])
class.col <- ifelse(X.train.DA$class==1, y = 53,
n = ifelse(X.train.DA$class==2, y = 68, n = ifelse(X.train.DA$class==3,y=203,n=464)))
### Fit an LDA model using the lda() funtion from the MASS package. This
### function uses predictor/response syntax.
fit.lda <- lda(X.train.DA, Y.train)
### We can plot the data using the linear discriminants. It's best to
### include colors. Let's just recycle the colors from above.
### There is no simple way to change the axis labels. Sometimes we just need
### to live with the defaults.
plot(fit.lda, col = class.col)
### We can also get histograms of the data along the main linear
### discriminant by setting type="histogram" and setting dimen=1.
plot(fit.lda, type = "histogram", dimen = 1)
X.train.DA$class
X.train.DA
class.col <- ifelse(set1$class==1, y = 53,
n = ifelse(set1$class==2, y = 68, n = ifelse(set1$class==3,y=203,n=464)))
### We can plot the data using the linear discriminants. It's best to
### include colors. Let's just recycle the colors from above.
### There is no simple way to change the axis labels. Sometimes we just need
### to live with the defaults.
plot(fit.lda, col = class.col)
### We can also get histograms of the data along the main linear
### discriminant by setting type="histogram" and setting dimen=1.
plot(fit.lda, type = "histogram", dimen = 1)
plot(fit.lda, type = "histogram", dimen = 1)
### We can also add smoothed density curves to these histograms by setting
### type="both".
plot(fit.lda, type = "both", dimen = 1)
### We can plot the data using the linear discriminants. It's best to
### include colors. Let's just recycle the colors from above.
### There is no simple way to change the axis labels. Sometimes we just need
### to live with the defaults.
plot(fit.lda, col = class.col)
plot(fit.lda, col = class.col)
set$1class
set1$class
set1$class == 1
remove(list=ls())
setwd("C:/Users/terry/Desktop/STAT-452/Class Examples")
# Discriminant Analysis on Wheat Data
##########
# Enter data and do some processing
wheat <- read.csv("wheat.csv")
# Discriminant Analysis on Wheat Data
##########
# Enter data and do some processing
wheat <- read.csv("Datasets/wheat.csv")
head(wheat)
# Variable "type" is the response variable.  "class" is another explanatory.
class(wheat$type)
wheat$type <- as.factor(wheat$type)
wheat$class <- as.factor(wheat$class)
# Create a numerical version of "class" for methods that need numbers
wheat$classnum <- as.numeric((wheat$class))
# Remove "id"
wheat <- wheat[, -1]
# multinom() requires numerical explanatories, so remove factor class
# Creating TWO sets: 200 train, 75 test
set.seed(67982193)
perm <- sample(x = nrow(wheat))
set1 <- wheat[which(perm <= 200), -1]
set2 <- wheat[which(perm > 200), -1]
##  "prior=" allows you to set prior probabilities if they are known.
#  Default is the sample proportions.
##
## Note that in fit below, the "Linear Discriminants" are directions
#   of the 2-dim subspace within which the 3 centroids (p-dim means) lie.
#   (kind of like PC's but different)
# The proportion of trace is the amount of variability from
#    conditional Multivariate Normals explained in each direction.
#
###############################################################
library(MASS)
set1s <- apply(set1[, -6], 2, scale)
set1s <- data.frame(set1s, type = set1$type)
lda.fit.s <- lda(data = set1s, type ~ .)
lda.fit.s
# Fit gives identical results as without scaling, but
#  can't interpret means
lda.fit <- lda(x = set1[, -6], grouping = set1$type)
lda.fit
# Plot results.  Create standard colours for classes.
class.col <- ifelse(set1$type == "Healthy", y = 53, n =
ifelse(set1$type == "Scab", y = 68, n = 203)
)
plot(lda.fit, dimen = 1, type = "histogram")
plot(lda.fit, dimen = 1, type = "density")
plot(lda.fit, col = colors()[class.col])
# Calculate in-sample and out-of-sample misclassification error
lda.pred.train <- predict(lda.fit, newdata = set1[, -6])$class
set1$type
class.col <- ifelse(set1$class=='2D', y = 53,
n = ifelse(set1$class=='4D', y = 68, n = ifelse(set1$class=='BUS',y=203,n=464)))
remove(list=ls())
knitr::opts_chunk$set(echo = TRUE)
vehdata <- read.csv("vehicle.csv")
summary(vehdata)
vehdata$class = factor(vehdata$class, labels=c('2D', '4D', 'BUS', 'VAN'))
summary(vehdata$class)
cor(vehdata[,1:18])
set.seed(46685326, kind = "Mersenne-Twister")
perm <- sample(x = nrow(vehdata))
set1 <- vehdata[which(perm <= 3*nrow(vehdata)/4), ]
set2 <- vehdata[which(perm > 3*nrow(vehdata)/4), ]
head(set1)
head(set2)
library(FNN)
### Split up the predictor variables from the class labels.
X.train.raw = set1[, -19]
X.valid.raw = set2[, -19]
Y.train = set1[, 19]
Y.valid = set2[, 19]
### KNN is based on distances. If variables are measured on different
### scales, we can change which points are neighbours by measuring
### in different units.
### a function we can use to rescale the columns of
### a data frame to have mean 0 and SD 1. We can also use it to rescale
### a data frame based on the means and SDs of another (this is useful
### for scaling the validation set to match the training set).
### Rescale x1 using the means and SDs of x2
scale.1 <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- mean(x2[, col])
b <- sd(x2[, col])
x1[, col] <- (x1[, col] - a) / b
}
x1
}
### Rescale our training and validation sets
X.train <- scale.1(X.train.raw, X.train.raw)
X.valid <- scale.1(X.valid.raw, X.train.raw) # Watch the order
### Now we can fit a KNN model using the knn function in the FNN
### package. The syntax of the knn function is a bit different from
### what we're used to. The first two inputs are the training and
### validation predictor matrices. The third input is the class labels
### for the training set. We can also set k to the number of
### neighbours we want. The function then outputs predicted class
### labels for the validation set. Let's use 1 neighbour.
pred.knn <- knn(X.train, X.valid, Y.train, k = 1)
### Let's make a confusion matrix. We get this using the table()
### function and providing both the predicted and true class labels
### for the validation set. We can also set the axis labels using
### the dnn input.
table(pred.knn, Y.valid, dnn = c("Predicted", "Observed"))
### Next, let's get the misclassification rate
(misclass.knn <- mean(pred.knn != Y.valid))
(se.knn <- sapply(misclass.knn, function(r) {
sqrt(r * (1 - r) / nrow(X.train))
}))
### Rescale the columns of x1 so that the columns of x2 fall between 0 and 1
rescale <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- min(x2[, col])
b <- max(x2[, col])
x1[, col] <- (x1[, col] - a) / (b - a)
}
x1
}
### Create copies of our datasets and rescale
data.train.scale <- set1
data.valid.scale <- set2
data.train.scale[, -19] <- rescale(data.train.scale[, -19], data.train[, -19])
data.train.scale[, -19] <- rescale(data.train.scale[, -19], set1[, -19])
data.valid.scale[, -19] <- rescale(data.valid.scale[, -19], set1[, -19])
summary(data.train.scale[,1:3])
summary(data.train.scale[,1:3])
### Create copies of our datasets and rescale
data.train.scale <- set1
data.valid.scale <- set2
data.train.scale[, -19] <- rescale(data.train.scale[, -19], set1[, -19])
data.valid.scale[, -19] <- rescale(data.valid.scale[, -19], set1[, -19])
summary(data.train.scale[,1:3])
summary(data.train.scale[,1:3])
### Create copies of our datasets and rescale
data.train.scale <- set1
data.valid.scale <- set2
data.train.scale[, -19] <- rescale(data.train.scale[, -19], set1[, -19])
data.valid.scale[, -19] <- rescale(data.valid.scale[, -19], set1[, -19])
summary(data.train.scale[,1:3])
summary(data.train.scale[,1:3])
```
summary(data.train.scale[,1:3])
### Rescale the columns of x1 so that the columns of x2 fall between 0 and 1
rescale <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- min(x2[, col])
b <- max(x2[, col])
x1[, col] <- (x1[, col] - a) / (b - a)
}
x1
}
### Create copies of our datasets and rescale
data.train.scale <- set1
data.valid.scale <- set2
data.train.scale[, -19] <- rescale(data.train.scale[, -19], set1[, -19])
data.valid.scale[, -19] <- rescale(data.valid.scale[, -19], set1[, -19])
summary(data.train.scale[,1:3])
summary(data.train.scale[,1:3])
knitr::opts_chunk$set(echo = TRUE)
vehdata <- read.csv("vehicle.csv")
summary(vehdata)
vehdata$class = factor(vehdata$class, labels=c('2D', '4D', 'BUS', 'VAN'))
summary(vehdata$class)
cor(vehdata[,1:18])
set.seed(46685326, kind = "Mersenne-Twister")
perm <- sample(x = nrow(vehdata))
set1 <- vehdata[which(perm <= 3*nrow(vehdata)/4), ]
set2 <- vehdata[which(perm > 3*nrow(vehdata)/4), ]
head(set1)
head(set2)
library(FNN)
### Split up the predictor variables from the class labels.
X.train.raw = set1[, -19]
X.valid.raw = set2[, -19]
Y.train = set1[, 19]
Y.valid = set2[, 19]
### KNN is based on distances. If variables are measured on different
### scales, we can change which points are neighbours by measuring
### in different units.
### a function we can use to rescale the columns of
### a data frame to have mean 0 and SD 1. We can also use it to rescale
### a data frame based on the means and SDs of another (this is useful
### for scaling the validation set to match the training set).
### Rescale x1 using the means and SDs of x2
scale.1 <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- mean(x2[, col])
b <- sd(x2[, col])
x1[, col] <- (x1[, col] - a) / b
}
x1
}
### Rescale our training and validation sets
X.train <- scale.1(X.train.raw, X.train.raw)
X.valid <- scale.1(X.valid.raw, X.train.raw) # Watch the order
### Now we can fit a KNN model using the knn function in the FNN
### package. The syntax of the knn function is a bit different from
### what we're used to. The first two inputs are the training and
### validation predictor matrices. The third input is the class labels
### for the training set. We can also set k to the number of
### neighbours we want. The function then outputs predicted class
### labels for the validation set. Let's use 1 neighbour.
pred.knn <- knn(X.train, X.valid, Y.train, k = 1)
### Let's make a confusion matrix. We get this using the table()
### function and providing both the predicted and true class labels
### for the validation set. We can also set the axis labels using
### the dnn input.
table(pred.knn, Y.valid, dnn = c("Predicted", "Observed"))
### Next, let's get the misclassification rate
(misclass.knn <- mean(pred.knn != Y.valid))
(se.knn <- sapply(misclass.knn, function(r) {
sqrt(r * (1 - r) / nrow(X.train))
}))
### Rescale the columns of x1 so that the columns of x2 fall between 0 and 1
rescale <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- min(x2[, col])
b <- max(x2[, col])
x1[, col] <- (x1[, col] - a) / (b - a)
}
x1
}
### Create copies of our datasets and rescale
data.train.scale <- set1
data.valid.scale <- set2
data.train.scale[, -19] <- rescale(data.train.scale[, -19], set1[, -19])
data.valid.scale[, -19] <- rescale(data.valid.scale[, -19], set1[, -19])
summary(data.train.scale[,1:3])
summary(data.train.scale[,1:3])
library(nnet)
library(car)
library(glmnet)
library(MASS)
fit.log.nnet <- multinom(class ~ ., data = data.train.scale)
Anova(fit.log.nnet)
pred.log.nnet <- predict(fit.log.nnet, data.valid.scale)
misclass.log.nnet <- mean(pred.log.nnet != Y.valid)
(misclass.log.se <- sapply(misclass.log.nnet, function(r) {
sqrt(r * (1 - r) / nrow(X.train))
}))
table(Y.valid, pred.log.nnet, ### Confusion matrix
dnn = c("Observed", "Predicted")
)
misclass.log.nnet
### The glmnet() function uses predictor matrix/response vector syntax,
### so we need to extract these from our training and validation sets.
### We also have to convert the predictors to a matrix using the
### as.matrix() function.
X.train.scale <- as.matrix(data.train.scale[, -19])
Y.train <- data.train.scale[, 19]
X.valid.scale <- as.matrix(data.valid.scale[, -19])
Y.valid <- data.valid.scale[, 19]
### While we're looking at the glmnet package, let's do LASSO. We need to
### choose lambda using CV. Fortunately, the cv.glmnet() function does this
### for us. The syntax for cv.glmnet() is the same as for glmnet().
fit.CV.lasso <- cv.glmnet(X.train.scale, Y.train, family = "multinomial")
### The CV-min values are stored in the output from
### cv.glmnet()
lambda.min <- fit.CV.lasso$lambda.min
### Let's check which predictors are included in each "best" model. We
### can get the coefficients using the coef() function, setting s to
### the appropriate lambda value.
coef(fit.CV.lasso, s = lambda.min)
### Now we can get predictions for both "best" models
pred.lasso.min <- predict(fit.CV.lasso, X.valid.scale,
s = lambda.min,
type = "class"
)
table(Y.valid, pred.lasso.min, dnn = c("Obs", "Pred"))
miss.lasso.min <- mean(Y.valid != pred.lasso.min)
(se.miss.lasso.min <- sapply(miss.lasso.min, function(r) {
sqrt(r * (1 - r) / nrow(X.train.scale))
}))
### For discriminant analysis, it's best to scale predictors
### to have mean 0 and SD 1 (this makes the results easier to
### interpret). We can do this using using the following function.
### Rescale x1 using the means and SDs of x2
scale.1 <- function(x1, x2) {
for (col in 1:ncol(x1)) {
a <- mean(x2[, col])
b <- sd(x2[, col])
x1[, col] <- (x1[, col] - a) / b
}
x1
}
X.train.DA <- scale.1(data.train[, -19], data.train[, -19])
X.train.DA <- scale.1(data.train[, -19], set1[, -19])
X.train.DA <- scale.1(set1[, -19], set1[, -19])
X.valid.DA <- scale.1(set2[, -19], set1[, -19])
class.col <- ifelse(set1$class=='2D', y = 53,
n = ifelse(set1$class=='4D', y = 68, n = ifelse(set1$class=='BUS',y=203,n=464)))
### Fit an LDA model using the lda() funtion from the MASS package. This
### function uses predictor/response syntax.
fit.lda <- lda(X.train.DA, Y.train)
### We can plot the data using the linear discriminants. It's best to
### include colors. Let's just recycle the colors from above.
### There is no simple way to change the axis labels. Sometimes we just need
### to live with the defaults.
plot(fit.lda, col = class.col)
plot(fit.lda, col = class.col)
plot(fit.lda, type = "histogram", dimen = 1)
### We can also add smoothed density curves to these histograms by setting
### type="both".
plot(fit.lda, type = "both", dimen = 1)
### We can also get histograms of the data along the main linear
### discriminant by setting type="histogram" and setting dimen=1.
plot(fit.lda, type = "histogram", dimen = 1)
plot(fit.lda, col = class.col)
plot(fit.lda, type = "histogram", dimen = 1)
plot(fit.lda, type = "histogram", dimen = 2)
### We can also add smoothed density curves to these histograms by setting
### type="both".
plot(fit.lda, type = "both", dimen = 1)
plot(fit.lda, col = class.col)
### We get predictions by extracting the class object from the predict()
### function's output.
pred.lda <- predict(fit.lda, X.valid.DA)$class
table(Y.valid, pred.lda, dnn = c("Obs", "Pred"))
miss.lda <- mean(Y.valid != pred.lda)
(se.miss.lda <- sapply(miss.lda, function(r) {
sqrt(r * (1 - r) / nrow(X.train.DA))
}))
miss.lda <- mean(Y.valid != pred.lda)
(miss.lda <- mean(Y.valid != pred.lda))
(miss.lasso.min <- mean(Y.valid != pred.lasso.min))
(misclass.log.nnet <- mean(pred.log.nnet != Y.valid))
